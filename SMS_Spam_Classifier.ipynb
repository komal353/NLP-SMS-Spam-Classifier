{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem - Identify whether the message is spam or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection - The data is collected from UCI repository, the data obtained was in tab separated format, \n",
    "url for which is given below:\n",
    "https://archive.ics.uci.edu/ml/datasets/sms+spam+collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the data\n",
    "msg=pd.read_csv('/Users/komalrungta/Downloads/smsspamcollection/SMSSpamCollection',sep='\\t',names=['labels','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                            message\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6    ham  Even my brother is not like to speak with me. ...\n",
       "7    ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the data\n",
    "msg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and preprocessing\n",
    "message column has lot of comma,full stop,question mark,some words in capital letter, words like 'the','to','an','we',\n",
    "etc. which are not considered as a good indicator of spam classifier. Below are the few techniques we are going to apply:-\n",
    "\n",
    "* lower the sentence\n",
    "* We are going to remove stopwords\n",
    "* Stemming\n",
    "* create a bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import re  ## to remove comma,full stop,question mark\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate Stemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate corpus after cleaning\n",
    "corpus=[]\n",
    "for i in range (0 , len(msg)):\n",
    "    review=re.sub('[^a-zA-Z]','',msg['message'][i])\n",
    "    review=review.lower()  ##lowercase\n",
    "    review=review.split()  ## split each & every sentences to get list of words\n",
    "    review=[ps.stem(word) for word in review if word not in stopwords.words('english')]#remove stopwords & do stemming\n",
    "    review=' '.join(review) ## to join list of words to sentence\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imgonnabehomesoonandidontwanttotalkaboutthisstuffanymoretonightkivecriedenoughtoday'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## view a corpus\n",
    "corpus[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5080)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "## initialize CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(corpus).toarray()\n",
    "## check the shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This indicates that there are 5080 columns (words) in X out of which only some of the words may not be frequently present, so lets take only 3500 columns initially to create our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initialize CountVectorizer with max_features = 3500\n",
    "cv=CountVectorizer(max_features = 3500)\n",
    "X=cv.fit_transform(corpus).toarray()\n",
    "## check the shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ham  spam\n",
       "0    1     0\n",
       "1    1     0\n",
       "2    0     1\n",
       "3    1     0\n",
       "4    1     0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## encoding our target variable\n",
    "y=pd.get_dummies(msg.labels)\n",
    "## check y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It's encoding 'ham' to '1' and spam to '0' when message is 'ham' and vice-versa.\n",
    "##### let's have only one representation of the target feature instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## let's represent y with 'spam' only, spam = 0 means its 'ham', if spam = 1 means its 'spam'\n",
    "y=y.iloc[:,1].values\n",
    "## check y\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 3500), (1115, 3500), (4457,), (1115,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "## check the size of the splits\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to solve the problem we are using Naive Bayes as it works very well w.r.t NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "## initialize the model\n",
    "spam_detect_model=MultinomialNB()\n",
    "## fit the data\n",
    "spam_detect_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make predictions\n",
    "y_pred=spam_detect_model.predict(X_test)\n",
    "## check y_pred\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[955,   0],\n",
       "       [156,   4]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax,cmap='coolwarm');  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "#ax.xaxis.set_ticklabels(['ham', 'spam']); ax.yaxis.set_ticklabels(['ham', 'spam']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8600896860986547"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's check accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imgonnabehomesoonandidontwanttotalkaboutthisstuffanymoretonightkivecriedenoughtoday'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Let's try to improve it with lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "## initializing\n",
    "lem=WordNetLemmatizer()\n",
    "## generate corpus after cleaning\n",
    "corpus_lem=[]\n",
    "for i in range (0 , len(msg)):\n",
    "    review_lem=re.sub('[^a-zA-Z]','',msg['message'][i])\n",
    "    review_lem=review_lem.lower()  ##lowercase\n",
    "    review_lem=review_lem.split()  ## split each & every sentences to get list of words\n",
    "    review_lem=[lem.lemmatize(word) for word in review_lem if word not in stopwords.words('english')]#remove stopwords & do stemming\n",
    "    review_lem=' '.join(review_lem) ## to join list of words to sentence\n",
    "    corpus_lem.append(review_lem)\n",
    "## view a corpus\n",
    "corpus_lem[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create bag of words\n",
    "X_lem=cv.fit_transform(corpus_lem).toarray()\n",
    "## check the shape of X\n",
    "X_lem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 3500), (1115, 3500), (4457,), (1115,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create train train split\n",
    "X_lem_train,X_lem_test,y_lem_train,y_lem_test=train_test_split(X_lem,y,test_size=0.2,random_state=0)\n",
    "## check the size of the splits\n",
    "X_lem_train.shape,X_lem_test.shape,y_lem_train.shape,y_lem_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create model\n",
    "spam_detect_model.fit(X_lem_train,y_lem_train)\n",
    "## Make predictions\n",
    "y_pred_lem=spam_detect_model.predict(X_lem_test)\n",
    "## check y_pred\n",
    "y_pred_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[955,   0],\n",
       "       [156,   4]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create confusion matrix\n",
    "cm_lem = confusion_matrix(y_lem_test, y_pred_lem)\n",
    "cm_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8600896860986547"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's check accuracy\n",
    "accuracy_lem=accuracy_score(y_lem_test, y_pred_lem)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No difference seen in False negative or accuracy, let's now include all the features as initially we took only 3500 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 5080), (5572, 5080))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initialize CountVectorizer without max_features\n",
    "cv=CountVectorizer()\n",
    "## Independent variable (Stemming)\n",
    "X=cv.fit_transform(corpus).toarray()\n",
    "## Independent variable (Lemmatization)\n",
    "X_lem=cv.fit_transform(corpus_lem).toarray()\n",
    "## check the shape of X\n",
    "X.shape,X_lem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 5080),\n",
       " (1115, 5080),\n",
       " (4457,),\n",
       " (1115,),\n",
       " (4457, 5080),\n",
       " (1115, 5080),\n",
       " (4457,),\n",
       " (1115,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train test split (stemming)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "## train test split (Lemmatization)\n",
    "X_lem_train,X_lem_test,y_lem_train,y_lem_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "## check the shape\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape,X_lem_train.shape,X_lem_test.shape,y_lem_train.shape,y_lem_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fit the model (stemming)\n",
    "spam_detect_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make predictions\n",
    "y_pred=spam_detect_model.predict(X_test)\n",
    "## check y_pred\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[955,   0],\n",
       "       [156,   4]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8600896860986547"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's check accuracy\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create model (lemmatization)\n",
    "spam_detect_model.fit(X_lem_train,y_lem_train)\n",
    "## Make predictions\n",
    "y_pred_lem=spam_detect_model.predict(X_lem_test)\n",
    "## check y_pred\n",
    "y_pred_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[955,   0],\n",
       "       [156,   4]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create confusion matrix\n",
    "cm_lem = confusion_matrix(y_lem_test, y_pred_lem)\n",
    "cm_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8600896860986547"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's check accuracy\n",
    "accuracy_lem=accuracy_score(y_lem_test, y_pred_lem)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can't see any improvement in FN and accuracy so let's try with TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating X and y\n",
    "X=msg.message\n",
    "y=msg.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahhhh',\n",
       " 'ahmad',\n",
       " 'ahold',\n",
       " 'aid',\n",
       " 'aids',\n",
       " 'aig',\n",
       " 'aight',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "## instantiate\n",
    "tf_idf=TfidfVectorizer()\n",
    "## fitting and transforming the data to change the data\n",
    "X=tf_idf.fit_transform(X) \n",
    "## getting the features name\n",
    "tf_idf.get_feature_names()[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8713)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## getting the feature vectores\n",
    "X=X.toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating training and testing\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model creation\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb=BernoulliNB(alpha=0.01) ## model object creation\n",
    "nb.fit(X_train,y_train) ## fitting the model\n",
    "y_hat=nb.predict(X_test) ## getting the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1444</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>12</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    ham  spam\n",
       "labels            \n",
       "ham     1444     4\n",
       "spam      12   212"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## confusion matrix\n",
    "pd.crosstab(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1448\n",
      "        spam       0.98      0.95      0.96       224\n",
      "\n",
      "    accuracy                           0.99      1672\n",
      "   macro avg       0.99      0.97      0.98      1672\n",
      "weighted avg       0.99      0.99      0.99      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## model evalution\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904306220095693"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the accuracy\n",
    "accuracy_score(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: We obtained better accuracy while using TF-IDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
